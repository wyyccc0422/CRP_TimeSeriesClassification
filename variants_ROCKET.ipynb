{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from utils import dfwellgr,marker_ssig,extract_signature_Xy,plot_simple\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import For Classification \n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "#Import For Testing \n",
    "from utils import window, plot_pred_distribution\n",
    "from constraints import get_markers_rocket_order_with_constraint\n",
    "from utils import recall_tops,find_optimal_tolerance,get_markers_rocket_order\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD Data and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Testing Data\n",
    "df_test_log = pd.read_parquet('testdata/logs_50.parquet', engine='fastparquet')\n",
    "df_test_log.loc[df_test_log['GR'] < -1, 'GR' ] = -1\n",
    "df_test_log.loc[df_test_log['GR'] > 400, 'GR' ] = 400\n",
    "\n",
    "df_test_loc = pd.read_parquet('testdata/loc_50.parquet', engine='fastparquet')\n",
    "df_test_loc = df_test_loc.reset_index()\n",
    "\n",
    "df_test_log = df_test_loc.merge(df_test_log, how = 'inner', left_on = 'wellName', right_on = 'wellName')\n",
    "\n",
    "df_test_tops = pd.read_csv('testdata/tops_50.csv')\n",
    "df_test_tops = df_test_tops.set_index('wellName')\n",
    "cols = ['MARCEL', 'SYLVAIN', 'CONRAD']\n",
    "df_test_tops = df_test_tops[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tops = pd.read_parquet('Training/tops.parquet', engine='fastparquet')\n",
    "cols = ['MARCEL', 'SYLVAIN', 'CONRAD']\n",
    "df_tops = df_tops[cols]\n",
    "df_tops.dropna(inplace = True)\n",
    "df_tops[df_tops['CONRAD'] - df_tops['SYLVAIN'] < 0] #Here we can see incorrect data\n",
    "\n",
    "well_array = np.load('hackaton_training_well_one.npy', allow_pickle=True)\n",
    "df_tops = df_tops[df_tops.index.isin(well_array[0][0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini ROCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evolution of ROCKET, MINIROCKET [6], is proposed as the new default variant of ROCKET by its authors and utilizes only one feature per kernel (percentage of positive values), thereby halving the features. It also utilizes other optimizations to speed up ROCKET in general and follows a minimally random approach with a given set of kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.panel.rocket import MiniRocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming time for mini ROCKET: 1.9297661781311035\n"
     ]
    }
   ],
   "source": [
    "#Load Prepared Data\n",
    "X = np.load('prepared_data/X_201.npy')\n",
    "y = np.load('prepared_data/y_201.npy')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train,y_train = X,y\n",
    "minirocket = MiniRocket(num_kernels=10000) \n",
    "minirocket.fit(X_train) \n",
    "\n",
    "start = time.time()\n",
    "X_train_transformed = minirocket.transform(X_train) \n",
    "et = time.time() - start\n",
    "print(f'Transforming time for mini ROCKET: {et}')\n",
    "\n",
    "X_test_transformed = minirocket.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 9996)\n",
      " 1 eps: 1.00E-06  C: 1.00E-02   train_acc: 1.00000  valid_acc: 1.00000\n"
     ]
    }
   ],
   "source": [
    "#Ridge\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "\n",
    " #XGBoost classifier\n",
    "eps = 1e-6\n",
    "\n",
    "# normalize 'per feature'\n",
    "f_mean = X_train_transformed.mean(axis=0)\n",
    "f_std = X_train_transformed.std(axis=0) + eps\n",
    "X_train_norm = (X_train_transformed - f_mean) / f_std\n",
    "X_valid_norm = (X_test_transformed - f_mean) / f_std\n",
    "print(X_train_norm.shape)\n",
    "\n",
    "classifier_xgb = xgb.XGBClassifier(max_depth=5, n_estimators=100,n_jobs=-1)\n",
    "classifier_xgb.fit(X_train_norm, y_train)\n",
    "preds = classifier_xgb.predict(X_valid_norm)\n",
    "\n",
    "(preds == y_test).mean()\n",
    "\n",
    "##logistic regression\n",
    "\n",
    "eps = 1e-6\n",
    "C = 1e-2\n",
    "f_mean = X_train_transformed.mean(axis=0)\n",
    "f_std = X_train_transformed.std(axis=0) + eps  # epsilon to avoid dividing by 0\n",
    "X_train_tfm2 = (X_train_transformed - f_mean) / f_std\n",
    "X_valid_tfm2 = (X_test_transformed - f_mean) / f_std\n",
    "classifier = LogisticRegression(penalty='l2', C=C, n_jobs=-1)\n",
    "classifier.fit(X_train_tfm2, y_train)\n",
    "probas = classifier.predict_proba(X_train_tfm2)\n",
    "train_score = classifier.score(X_train_tfm2, y_train)\n",
    "val_score = classifier.score(X_valid_tfm2, y_test)\n",
    "print('{:2} eps: {:.2E}  C: {:.2E}   train_acc: {:.5f}  valid_acc: {:.5f}'.format(1, eps, C, train_score, val_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time take 170.79497694969177\n"
     ]
    }
   ],
   "source": [
    "#create the predicted_tops for all well, by looping trough the list\n",
    "\n",
    "wsize = 201\n",
    "input_variable=['GR']\n",
    "pred_column = ['None','Marcel', 'Sylvain', 'Conrad']\n",
    "df_tops_pred = pd.DataFrame(pd.DataFrame(columns = ['wellName','MARCEL', 'SYLVAIN', 'CONRAD']))\n",
    "\n",
    "start = time.time()\n",
    "for well in df_test_tops.index:\n",
    "    print(well)\n",
    "    pred_m, df_wm = get_markers_rocket_order(f_mean, f_std, df_test_log, well, pred_column, wsize, input_variable, minirocket, classifier_xgb, classifier,xgb = True)\n",
    "    print(pred_m)\n",
    "    row = {'wellName':well, 'MARCEL':pred_m[0], 'SYLVAIN':pred_m[1], 'CONRAD':pred_m[2]}\n",
    "    row_df = pd.DataFrame([row])\n",
    "    df_tops_pred = pd.concat([df_tops_pred, row_df], axis = 0, ignore_index = \"True\")\n",
    "\n",
    "clear_output()\n",
    "ext = time.time() - start\n",
    "print('Total time take',ext)\n",
    "df_tops_pred['wellName']  = df_tops_pred['wellName'].astype(float)\n",
    "df_tops_pred = df_tops_pred.sort_values(by = ['wellName']).reset_index().drop(['index'], axis = 1)\n",
    "df_tops_pred = df_tops_pred.set_index('wellName')\n",
    "#df_tops_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tolerance 20, recall 0.9866666666666667, mae 5.406666666666666\n",
      "tolerance 15, recall 0.9866666666666667, mae 5.406666666666666\n",
      "tolerance 10, recall 0.94, mae 5.406666666666666\n",
      "tolerance 5, recall 0.7733333333333333, mae 5.406666666666666\n",
      "Largest Error MARCEL: 53.0\n",
      "Largest Error SYLVAIN: 14.0\n",
      "Largest Error CONRAD: 234.0\n",
      "Optimal Tolerance : 234\n"
     ]
    }
   ],
   "source": [
    "#call the evaluate function\n",
    "tr = [20, 15, 10, 5]\n",
    "for tolerance in tr:\n",
    "#recall is percentage of positive values that is correclty identified,\n",
    "# so true positive/ sum of num_all positive\n",
    "    recall, mae, df_result = recall_tops(df_test_tops,df_tops_pred,tolerance)\n",
    "    print(\"tolerance {0}, recall {1}, mae {2}\".format(tolerance, recall, mae))\n",
    "\n",
    "optimal_tolerance = find_optimal_tolerance(df_test_tops, df_tops_pred)\n",
    "print(f\"Largest Error MARCEL: {df_result['MARCEL_ae'].max()}\")\n",
    "print(f\"Largest Error SYLVAIN: {df_result['SYLVAIN_ae'].max()}\")\n",
    "print(f\"Largest Error CONRAD: {df_result['CONRAD_ae'].max()}\")\n",
    "print(\"Optimal Tolerance :\", optimal_tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time take 177.8295192718506\n"
     ]
    }
   ],
   "source": [
    "#Predict ALL WITH CONSTRAINTS\n",
    "#create the predicted_tops for all well, by looping trough the list\n",
    "wsize = 201\n",
    "input_variable=['GR']\n",
    "pred_column = ['None','Marcel', 'Sylvain', 'Conrad']\n",
    "df_tops_pred = pd.DataFrame(pd.DataFrame(columns = ['wellName','MARCEL', 'SYLVAIN', 'CONRAD']))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for well in df_test_tops.index:\n",
    "    print(well)\n",
    "    pred_m, df_wm = get_markers_rocket_order_with_constraint(f_mean, f_std,df_tops, df_test_log, well, pred_column, wsize, input_variable, \n",
    "                                             s2s = False,\n",
    "                                             model = None, \n",
    "                                             xgb = True,\n",
    "                                             rocket = minirocket, \n",
    "                                             classifier_xgb = classifier_xgb, \n",
    "                                             classifier = classifier,\n",
    "                                             alpha=0.5, \n",
    "                                             confidence_level=0.96)\n",
    "    print(pred_m)\n",
    "    row = {'wellName':well, 'MARCEL':pred_m[0], 'SYLVAIN':pred_m[1], 'CONRAD':pred_m[2]}\n",
    "    row_df = pd.DataFrame([row])\n",
    "    df_tops_pred = pd.concat([df_tops_pred, row_df], axis = 0, ignore_index = \"True\")\n",
    "\n",
    "clear_output()\n",
    "ext = time.time() - start\n",
    "print('Total time take',ext)\n",
    "df_tops_pred['wellName']  = df_tops_pred['wellName'].astype(float)\n",
    "df_tops_pred = df_tops_pred.sort_values(by = ['wellName']).reset_index().drop(['index'], axis = 1)\n",
    "df_tops_pred = df_tops_pred.set_index('wellName')\n",
    "#df_tops_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tolerance 20, recall 0.9866666666666667, mae 4.2025333333333466\n",
      "tolerance 15, recall 0.98, mae 4.2025333333333466\n",
      "tolerance 10, recall 0.92, mae 4.2025333333333466\n",
      "tolerance 5, recall 0.7533333333333333, mae 4.2025333333333466\n",
      "Largest Error MARCEL: 53.0\n",
      "Largest Error SYLVAIN: 27.840000000000146\n",
      "Largest Error CONRAD: 14.0\n",
      "Optimal Tolerance : 53\n"
     ]
    }
   ],
   "source": [
    "#call the evaluate function\n",
    "tr = [20, 15, 10, 5]\n",
    "for tolerance in tr:\n",
    "#recall is percentage of positive values that is correclty identified,\n",
    "# so true positive/ sum of num_all positive\n",
    "    recall, mae, df_result = recall_tops(df_test_tops,df_tops_pred,tolerance)\n",
    "    print(\"tolerance {0}, recall {1}, mae {2}\".format(tolerance, recall, mae))\n",
    "\n",
    "optimal_tolerance = find_optimal_tolerance(df_test_tops, df_tops_pred)\n",
    "print(f\"Largest Error MARCEL: {df_result['MARCEL_ae'].max()}\")\n",
    "print(f\"Largest Error SYLVAIN: {df_result['SYLVAIN_ae'].max()}\")\n",
    "print(f\"Largest Error CONRAD: {df_result['CONRAD_ae'].max()}\")\n",
    "print(\"Optimal Tolerance :\", optimal_tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiROCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rocket.multi_rocket.multirocket import MultiRocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming time for multi ROCKET: 0.7307519912719727\n"
     ]
    }
   ],
   "source": [
    "#Load Prepared Data\n",
    "X = np.load('prepared_data/X_201.npy')\n",
    "y = np.load('prepared_data/y_201.npy')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[2]))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[2]))\n",
    "\n",
    "\n",
    "multirocket = MultiRocket(\n",
    "            num_kernels=1000\n",
    "        )\n",
    "    \n",
    "multirocket.fit(X_train_reshaped)\n",
    "start = time.time()\n",
    "X_train_transformed = multirocket.transform(X_train_reshaped)\n",
    "et = time.time() - start\n",
    "print(f'Transforming time for multi ROCKET: {et}')\n",
    "\n",
    "X_test_transformed = multirocket.transform(X_test_reshaped) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3367, 7392)\n",
      " 1 eps: 1.00E-06  C: 1.00E-02   train_acc: 1.00000  valid_acc: 1.00000\n"
     ]
    }
   ],
   "source": [
    "#Ridge\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "\n",
    " #XGBoost classifier\n",
    "eps = 1e-6\n",
    "\n",
    "# normalize 'per feature'\n",
    "f_mean = X_train_transformed.mean(axis=0)\n",
    "f_std = X_train_transformed.std(axis=0) + eps\n",
    "X_train_norm = (X_train_transformed - f_mean) / f_std\n",
    "X_valid_norm = (X_test_transformed - f_mean) / f_std\n",
    "print(X_train_norm.shape)\n",
    "\n",
    "classifier_xgb = xgb.XGBClassifier(max_depth=5, n_estimators=100,n_jobs=-1)\n",
    "classifier_xgb.fit(X_train_norm, y_train)\n",
    "preds = classifier_xgb.predict(X_valid_norm)\n",
    "\n",
    "(preds == y_test).mean()\n",
    "\n",
    "##logistic regression\n",
    "\n",
    "eps = 1e-6\n",
    "C = 1e-2\n",
    "f_mean = X_train_transformed.mean(axis=0)\n",
    "f_std = X_train_transformed.std(axis=0) + eps  # epsilon to avoid dividing by 0\n",
    "X_train_tfm2 = (X_train_transformed - f_mean) / f_std\n",
    "X_valid_tfm2 = (X_test_transformed - f_mean) / f_std\n",
    "classifier = LogisticRegression(penalty='l2', C=C, n_jobs=-1)\n",
    "classifier.fit(X_train_tfm2, y_train)\n",
    "probas = classifier.predict_proba(X_train_tfm2)\n",
    "train_score = classifier.score(X_train_tfm2, y_train)\n",
    "val_score = classifier.score(X_valid_tfm2, y_test)\n",
    "print('{:2} eps: {:.2E}  C: {:.2E}   train_acc: {:.5f}  valid_acc: {:.5f}'.format(1, eps, C, train_score, val_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time take 59.858306884765625\n"
     ]
    }
   ],
   "source": [
    "#Predict ALL WITH CONSTRAINTS\n",
    "#create the predicted_tops for all well, by looping trough the list\n",
    "wsize = 201\n",
    "input_variable=['GR']\n",
    "pred_column = ['None','Marcel', 'Sylvain', 'Conrad']\n",
    "df_tops_pred = pd.DataFrame(pd.DataFrame(columns = ['wellName','MARCEL', 'SYLVAIN', 'CONRAD']))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for well in df_test_tops.index:\n",
    "    print(well)\n",
    "    pred_m, df_wm = get_markers_rocket_order(f_mean, f_std, df_test_log, well, pred_column, wsize, input_variable, \n",
    "                                             multirocket, \n",
    "                                             classifier_xgb = classifier_xgb, \n",
    "                                             classifier = classifier,xgb=True)\n",
    "    print(pred_m)\n",
    "    row = {'wellName':well, 'MARCEL':pred_m[0], 'SYLVAIN':pred_m[1], 'CONRAD':pred_m[2]}\n",
    "    row_df = pd.DataFrame([row])\n",
    "    df_tops_pred = pd.concat([df_tops_pred, row_df], axis = 0, ignore_index = \"True\")\n",
    "\n",
    "clear_output()\n",
    "ext = time.time() - start\n",
    "print('Total time take',ext)\n",
    "df_tops_pred['wellName']  = df_tops_pred['wellName'].astype(float)\n",
    "df_tops_pred = df_tops_pred.sort_values(by = ['wellName']).reset_index().drop(['index'], axis = 1)\n",
    "df_tops_pred = df_tops_pred.set_index('wellName')\n",
    "#df_tops_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tolerance 20, recall 0.9866666666666667, mae 4.816666666666666\n",
      "tolerance 15, recall 0.98, mae 4.816666666666666\n",
      "tolerance 10, recall 0.9533333333333334, mae 4.816666666666666\n",
      "tolerance 5, recall 0.8466666666666667, mae 4.816666666666666\n",
      "Largest Error MARCEL: 52.0\n",
      "Largest Error SYLVAIN: 14.0\n",
      "Largest Error CONRAD: 231.0\n",
      "Optimal Tolerance : 231\n"
     ]
    }
   ],
   "source": [
    "#call the evaluate function\n",
    "tr = [20, 15, 10, 5]\n",
    "for tolerance in tr:\n",
    "#recall is percentage of positive values that is correclty identified,\n",
    "# so true positive/ sum of num_all positive\n",
    "    recall, mae, df_result = recall_tops(df_test_tops,df_tops_pred,tolerance)\n",
    "    print(\"tolerance {0}, recall {1}, mae {2}\".format(tolerance, recall, mae))\n",
    "\n",
    "optimal_tolerance = find_optimal_tolerance(df_test_tops, df_tops_pred)\n",
    "print(f\"Largest Error MARCEL: {df_result['MARCEL_ae'].max()}\")\n",
    "print(f\"Largest Error SYLVAIN: {df_result['SYLVAIN_ae'].max()}\")\n",
    "print(f\"Largest Error CONRAD: {df_result['CONRAD_ae'].max()}\")\n",
    "print(\"Optimal Tolerance :\", optimal_tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time take 59.90837502479553\n"
     ]
    }
   ],
   "source": [
    "#Predict ALL WITH CONSTRAINTS\n",
    "#create the predicted_tops for all well, by looping trough the list\n",
    "wsize = 201\n",
    "input_variable=['GR']\n",
    "pred_column = ['None','Marcel', 'Sylvain', 'Conrad']\n",
    "df_tops_pred = pd.DataFrame(pd.DataFrame(columns = ['wellName','MARCEL', 'SYLVAIN', 'CONRAD']))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for well in df_test_tops.index:\n",
    "    print(well)\n",
    "    pred_m, df_wm = get_markers_rocket_order_with_constraint(f_mean, f_std,df_tops, df_test_log, well, pred_column, wsize, input_variable, \n",
    "                                             s2s = False,\n",
    "                                             model = None, \n",
    "                                             xgb = True,\n",
    "                                             rocket = multirocket, \n",
    "                                             classifier_xgb = classifier_xgb, \n",
    "                                             classifier = classifier,\n",
    "                                             alpha=0.5, \n",
    "                                             confidence_level=0.96)\n",
    "    print(pred_m)\n",
    "    row = {'wellName':well, 'MARCEL':pred_m[0], 'SYLVAIN':pred_m[1], 'CONRAD':pred_m[2]}\n",
    "    row_df = pd.DataFrame([row])\n",
    "    df_tops_pred = pd.concat([df_tops_pred, row_df], axis = 0, ignore_index = \"True\")\n",
    "\n",
    "clear_output()\n",
    "ext = time.time() - start\n",
    "print('Total time take',ext)\n",
    "df_tops_pred['wellName']  = df_tops_pred['wellName'].astype(float)\n",
    "df_tops_pred = df_tops_pred.sort_values(by = ['wellName']).reset_index().drop(['index'], axis = 1)\n",
    "df_tops_pred = df_tops_pred.set_index('wellName')\n",
    "#df_tops_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tolerance 20, recall 0.9866666666666667, mae 3.6108666666666793\n",
      "tolerance 15, recall 0.98, mae 3.6108666666666793\n",
      "tolerance 10, recall 0.94, mae 3.6108666666666793\n",
      "tolerance 5, recall 0.82, mae 3.6108666666666793\n",
      "Largest Error MARCEL: 52.0\n",
      "Largest Error SYLVAIN: 30.340000000000146\n",
      "Largest Error CONRAD: 16.0\n",
      "Optimal Tolerance : 52\n"
     ]
    }
   ],
   "source": [
    "#call the evaluate function\n",
    "tr = [20, 15, 10, 5]\n",
    "for tolerance in tr:\n",
    "#recall is percentage of positive values that is correclty identified,\n",
    "# so true positive/ sum of num_all positive\n",
    "    recall, mae, df_result = recall_tops(df_test_tops,df_tops_pred,tolerance)\n",
    "    print(\"tolerance {0}, recall {1}, mae {2}\".format(tolerance, recall, mae))\n",
    "\n",
    "optimal_tolerance = find_optimal_tolerance(df_test_tops, df_tops_pred)\n",
    "print(f\"Largest Error MARCEL: {df_result['MARCEL_ae'].max()}\")\n",
    "print(f\"Largest Error SYLVAIN: {df_result['SYLVAIN_ae'].max()}\")\n",
    "print(f\"Largest Error CONRAD: {df_result['CONRAD_ae'].max()}\")\n",
    "print(\"Optimal Tolerance :\", optimal_tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightWaveS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rocket.lightwaves.lightwavesl1l2_functions import _generate_first_phase_kernels, _apply_2layer_kernels\n",
    "from rocket.lightwaves.lightwaves_utils import ScalePerChannel, anova_feature_selection, mrmr_feature_selection, ScalePerChannelTrain, \\\n",
    "    ckd_to_kernels, get_fixed_candidate_kernels, get_ckd_matrix_with_features\n",
    "\n",
    "from rocket.lightwaves.lightwaves import LightWaveS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming time for mini ROCKET: 0.815636157989502\n"
     ]
    }
   ],
   "source": [
    "X = np.load('prepared_data/X_201.npy')\n",
    "y = np.load('prepared_data/y_201.npy')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "lightwaves = LightWaveS(final_num_feat=1000)\n",
    "lightwaves.fit(X_train.astype(np.float32),y_train)\n",
    "\n",
    "start = time.time()\n",
    "X_train_transformed = lightwaves.transform(X_train.astype(np.float32))\n",
    "et = time.time() - start\n",
    "print(f'Transforming time for mini ROCKET: {et}')\n",
    "\n",
    "X_test_transformed = lightwaves.transform(X_test.astype(np.float32)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3367, 1000)\n",
      " 1 eps: 1.00E-06  C: 1.00E-02   train_acc: 0.99851  valid_acc: 0.99644\n"
     ]
    }
   ],
   "source": [
    "#Ridge\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "\n",
    " #XGBoost classifier\n",
    "eps = 1e-6\n",
    "\n",
    "# normalize 'per feature'\n",
    "f_mean = X_train_transformed.mean(axis=0)\n",
    "f_std = X_train_transformed.std(axis=0) + eps\n",
    "X_train_norm = (X_train_transformed - f_mean) / f_std\n",
    "X_valid_norm = (X_test_transformed - f_mean) / f_std\n",
    "print(X_train_norm.shape)\n",
    "\n",
    "classifier_xgb = xgb.XGBClassifier(max_depth=5, n_estimators=100,n_jobs=-1)\n",
    "classifier_xgb.fit(X_train_norm, y_train)\n",
    "preds = classifier_xgb.predict(X_valid_norm)\n",
    "\n",
    "(preds == y_test).mean()\n",
    "\n",
    "##logistic regression\n",
    "\n",
    "eps = 1e-6\n",
    "C = 1e-2\n",
    "f_mean = X_train_transformed.mean(axis=0)\n",
    "f_std = X_train_transformed.std(axis=0) + eps  # epsilon to avoid dividing by 0\n",
    "X_train_tfm2 = (X_train_transformed - f_mean) / f_std\n",
    "X_valid_tfm2 = (X_test_transformed - f_mean) / f_std\n",
    "classifier = LogisticRegression(penalty='l2', C=C, n_jobs=-1)\n",
    "classifier.fit(X_train_tfm2, y_train)\n",
    "probas = classifier.predict_proba(X_train_tfm2)\n",
    "train_score = classifier.score(X_train_tfm2, y_train)\n",
    "val_score = classifier.score(X_valid_tfm2, y_test)\n",
    "print('{:2} eps: {:.2E}  C: {:.2E}   train_acc: {:.5f}  valid_acc: {:.5f}'.format(1, eps, C, train_score, val_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time take 73.84032797813416\n"
     ]
    }
   ],
   "source": [
    "#Predict ALL WITHOUT CONSTRAINTS\n",
    "#create the predicted_tops for all well, by looping trough the list\n",
    "start = time.time()\n",
    "wsize = 201\n",
    "input_variable=['GR']\n",
    "pred_column = ['None','Marcel', 'Sylvain', 'Conrad']\n",
    "df_tops_pred = pd.DataFrame(pd.DataFrame(columns = ['wellName','MARCEL', 'SYLVAIN', 'CONRAD']))\n",
    "\n",
    "for well in df_test_tops.index:\n",
    "    print(well)\n",
    "    pred_m, df_wm = get_markers_rocket_order(f_mean, f_std, df_test_log, well, pred_column, wsize, input_variable, lightwaves, classifier_xgb, classifier,xgb = True)\n",
    "    print(pred_m)\n",
    "    row = {'wellName':well, 'MARCEL':pred_m[0], 'SYLVAIN':pred_m[1], 'CONRAD':pred_m[2]}\n",
    "    row_df = pd.DataFrame([row])\n",
    "    df_tops_pred = pd.concat([df_tops_pred, row_df], axis = 0, ignore_index = \"True\")\n",
    "\n",
    "clear_output()\n",
    "ext = time.time() - start\n",
    "print('Total time take',ext)\n",
    "df_tops_pred['wellName']  = df_tops_pred['wellName'].astype(float)\n",
    "df_tops_pred = df_tops_pred.sort_values(by = ['wellName']).reset_index().drop(['index'], axis = 1)\n",
    "df_tops_pred = df_tops_pred.set_index('wellName')\n",
    "#df_tops_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tolerance 20, recall 0.9866666666666667, mae 3.9366666666666665\n",
      "tolerance 15, recall 0.98, mae 3.9366666666666665\n",
      "tolerance 10, recall 0.9533333333333334, mae 3.9366666666666665\n",
      "tolerance 5, recall 0.8266666666666667, mae 3.9366666666666665\n",
      "Largest Error MARCEL: 26.0\n",
      "Largest Error SYLVAIN: 18.0\n",
      "Largest Error CONRAD: 116.0\n",
      "Optimal Tolerance : 116\n"
     ]
    }
   ],
   "source": [
    "#call the evaluate function\n",
    "tr = [20, 15, 10, 5]\n",
    "for tolerance in tr:\n",
    "#recall is percentage of positive values that is correclty identified,\n",
    "# so true positive/ sum of num_all positive\n",
    "    recall, mae, df_result = recall_tops(df_test_tops,df_tops_pred,tolerance)\n",
    "    print(\"tolerance {0}, recall {1}, mae {2}\".format(tolerance, recall, mae))\n",
    "\n",
    "optimal_tolerance = find_optimal_tolerance(df_test_tops, df_tops_pred)\n",
    "print(f\"Largest Error MARCEL: {df_result['MARCEL_ae'].max()}\")\n",
    "print(f\"Largest Error SYLVAIN: {df_result['SYLVAIN_ae'].max()}\")\n",
    "print(f\"Largest Error CONRAD: {df_result['CONRAD_ae'].max()}\")\n",
    "print(\"Optimal Tolerance :\", optimal_tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time take 79.01890397071838\n"
     ]
    }
   ],
   "source": [
    "#Predict ALL WITH CONSTRAINTS\n",
    "#create the predicted_tops for all well, by looping trough the list\n",
    "wsize = 201\n",
    "input_variable=['GR']\n",
    "pred_column = ['None','Marcel', 'Sylvain', 'Conrad']\n",
    "df_tops_pred = pd.DataFrame(pd.DataFrame(columns = ['wellName','MARCEL', 'SYLVAIN', 'CONRAD']))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for well in df_test_tops.index:\n",
    "    print(well)\n",
    "    pred_m, df_wm = get_markers_rocket_order_with_constraint(f_mean, f_std,df_tops, df_test_log, well, pred_column, wsize, input_variable, \n",
    "                                             s2s = False,\n",
    "                                             model = None, \n",
    "                                             xgb = True,\n",
    "                                             rocket = lightwaves, \n",
    "                                             classifier_xgb = classifier_xgb, \n",
    "                                             classifier = classifier,\n",
    "                                             alpha=0.5, \n",
    "                                             confidence_level=0.96)\n",
    "    print(pred_m)\n",
    "    row = {'wellName':well, 'MARCEL':pred_m[0], 'SYLVAIN':pred_m[1], 'CONRAD':pred_m[2]}\n",
    "    row_df = pd.DataFrame([row])\n",
    "    df_tops_pred = pd.concat([df_tops_pred, row_df], axis = 0, ignore_index = \"True\")\n",
    "\n",
    "clear_output()\n",
    "ext = time.time() - start\n",
    "print('Total time take',ext)\n",
    "df_tops_pred['wellName']  = df_tops_pred['wellName'].astype(float)\n",
    "df_tops_pred = df_tops_pred.sort_values(by = ['wellName']).reset_index().drop(['index'], axis = 1)\n",
    "df_tops_pred = df_tops_pred.set_index('wellName')\n",
    "#df_tops_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tolerance 20, recall 0.9866666666666667, mae 3.5420666666666816\n",
      "tolerance 15, recall 0.98, mae 3.5420666666666816\n",
      "tolerance 10, recall 0.94, mae 3.5420666666666816\n",
      "tolerance 5, recall 0.8, mae 3.5420666666666816\n",
      "Largest Error MARCEL: 26.0\n",
      "Largest Error SYLVAIN: 32.340000000000146\n",
      "Largest Error CONRAD: 14.0\n",
      "Optimal Tolerance : 33\n"
     ]
    }
   ],
   "source": [
    "#call the evaluate function\n",
    "tr = [20, 15, 10, 5]\n",
    "for tolerance in tr:\n",
    "#recall is percentage of positive values that is correclty identified,\n",
    "# so true positive/ sum of num_all positive\n",
    "    recall, mae, df_result = recall_tops(df_test_tops,df_tops_pred,tolerance)\n",
    "    print(\"tolerance {0}, recall {1}, mae {2}\".format(tolerance, recall, mae))\n",
    "\n",
    "optimal_tolerance = find_optimal_tolerance(df_test_tops, df_tops_pred)\n",
    "print(f\"Largest Error MARCEL: {df_result['MARCEL_ae'].max()}\")\n",
    "print(f\"Largest Error SYLVAIN: {df_result['SYLVAIN_ae'].max()}\")\n",
    "print(f\"Largest Error CONRAD: {df_result['CONRAD_ae'].max()}\")\n",
    "print(\"Optimal Tolerance :\", optimal_tolerance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
